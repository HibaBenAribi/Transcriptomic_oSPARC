{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing required dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (21.1.1)\n",
      "Collecting pip\n",
      "  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 28.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.1.1\n",
      "    Uninstalling pip-21.1.1:\n",
      "      Successfully uninstalled pip-21.1.1\n",
      "Successfully installed pip-22.2.2\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.3.5\n",
      "Collecting bioinfokit\n",
      "  Downloading bioinfokit-2.1.0.tar.gz (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.0/87.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from bioinfokit) (1.3.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from bioinfokit) (1.20.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from bioinfokit) (3.4.2)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting seaborn\n",
      "  Downloading seaborn-0.12.0-py3-none-any.whl (285 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.1/285.1 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib-venn\n",
      "  Downloading matplotlib-venn-0.11.7.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting textwrap3\n",
      "  Downloading textwrap3-0.9.2-py2.py3-none-any.whl (12 kB)\n",
      "Collecting adjustText\n",
      "  Downloading adjustText-0.7.3.tar.gz (7.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->bioinfokit) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->bioinfokit) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->bioinfokit) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->bioinfokit) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->bioinfokit) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->bioinfokit) (2021.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from seaborn->bioinfokit) (3.10.0.0)\n",
      "Collecting packaging>=21.3\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.8/233.8 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->bioinfokit) (1.14.0)\n",
      "Building wheels for collected packages: bioinfokit, adjustText, matplotlib-venn\n",
      "  Building wheel for bioinfokit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bioinfokit: filename=bioinfokit-2.1.0-py3-none-any.whl size=58650 sha256=23d652a163432c6d6b8ffcc0f7c49d29e424c6edb049b534c7bb5f6a08b3a4c1\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/81/e6/c8/a378f0c300eba657e42ae0df674e32e6d434d96a7eb765b067\n",
      "  Building wheel for adjustText (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for adjustText: filename=adjustText-0.7.3-py3-none-any.whl size=7099 sha256=e8fa77565953a281089b440f41cf46b723f9ff5922b4e11d1987bfd9bf3d6b8d\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/2f/98/32/afbf902d8f040fadfdf0a44357e4ab750afe165d873bf5893d\n",
      "  Building wheel for matplotlib-venn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for matplotlib-venn: filename=matplotlib_venn-0.11.7-py3-none-any.whl size=32154 sha256=9ae4e1b9df4f9067dbe7d985f16ef5b5daf1cbd13b61e5015a61eb2d536fbb4e\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/a8/2e/f9/6939e56698c94559ea6a2f5797cef8345981657b03cdfb8c72\n",
      "Successfully built bioinfokit adjustText matplotlib-venn\n",
      "Installing collected packages: textwrap3, threadpoolctl, tabulate, scipy, patsy, packaging, joblib, scikit-learn, statsmodels, seaborn, matplotlib-venn, adjustText, bioinfokit\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.9\n",
      "    Uninstalling packaging-20.9:\n",
      "      Successfully uninstalled packaging-20.9\n",
      "Successfully installed adjustText-0.7.3 bioinfokit-2.1.0 joblib-1.2.0 matplotlib-venn-0.11.7 packaging-21.3 patsy-0.5.3 scikit-learn-1.0.2 scipy-1.7.3 seaborn-0.12.0 statsmodels-0.13.2 tabulate-0.9.0 textwrap3-0.9.2 threadpoolctl-3.1.0\n",
      "Collecting goatools\n",
      "  Downloading goatools-1.2.3.tar.gz (15.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from goatools) (1.3.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from goatools) (1.20.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from goatools) (1.7.3)\n",
      "Collecting xlsxwriter\n",
      "  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.0/150.0 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: statsmodels in /opt/conda/lib/python3.7/site-packages (from goatools) (0.13.2)\n",
      "Collecting xlrd==1.2.0\n",
      "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: docopt in /opt/conda/lib/python3.7/site-packages (from goatools) (0.6.2)\n",
      "Collecting pydot\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from goatools) (2.22.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->goatools) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->goatools) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /opt/conda/lib/python3.7/site-packages (from pydot->goatools) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->goatools) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->goatools) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->goatools) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->goatools) (1.25.7)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from statsmodels->goatools) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.7/site-packages (from statsmodels->goatools) (21.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from patsy>=0.5.2->statsmodels->goatools) (1.14.0)\n",
      "Building wheels for collected packages: goatools\n",
      "  Building wheel for goatools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for goatools: filename=goatools-1.2.3-py3-none-any.whl size=15764707 sha256=1fe30959b7e8a039ac00a29dd7dc9c5f88e400a6acf80dfaca593eaea4309659\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/0b/59/dd/635dfe772e3359be7c53a00442da0959b7d5d76c75c928d560\n",
      "Successfully built goatools\n",
      "Installing collected packages: xlsxwriter, xlrd, pydot, goatools\n",
      "Killed\n"
     ]
    }
   ],
   "source": [
    "# You might need to re rerun this cell, if you see killed  at end of outcome of this cell\n",
    "!pip install --upgrade pip\n",
    "!pip install pandas\n",
    "!pip install bioinfokit\n",
    "!pip install goatools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from pylab import *\n",
    "from bioinfokit import analys, visuz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "from goatools.base import download_go_basic_obo\n",
    "from goatools.base import download_ncbi_associations\n",
    "from goatools.obo_parser import GODag\n",
    "from goatools.anno.genetogo_reader import Gene2GoReader\n",
    "from goatools.goea.go_enrichment_ns import GOEnrichmentStudyNS\n",
    "from simcore_sdk import node_ports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading files\n",
    "\n",
    "- The first file consist Gene, P.Value, Log FC columns\t\n",
    "- The second input file was download from [NCBI Gene](https://www.ncbi.nlm.nih.gov/gene/?term=%229606%22[Taxonomy+ID]+AND+alive[property]+AND+genetype+protein+coding[Properties]) and uploaded here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PORTS = await node_ports.ports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading /tmp/simcorefiles/outFile/gene_result_mm.txt [5802869 bytes]: 100%|██████████| 5.80M/5.80M [00:00<00:00, 43.2Mbyte/s]\n"
     ]
    }
   ],
   "source": [
    "input_1 = await(await PORTS.inputs)[0].get()\n",
    "input_2 = await(await PORTS.inputs)[1].get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_1 = await(await PORTS.outputs)[0].get()\n",
    "output_2 = await(await PORTS.outputs)[1].get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams[\"figure.figsize\"] = 20,16\n",
    "pvalue = 0.05\n",
    "logFC = 0\n",
    "# logFC = np.abs(logFC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-db3b1530f238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# data1[\"log10(PValue)\"] = -1*np.log10(data1[\"P.Value\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"expression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Not differentially expressed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"P.Value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mpvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Log FC\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mlogFC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"expression\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"Upregulated\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     )\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Invalid file path or buffer object type: {type(filepath_or_buffer)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     return IOArgs(\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "data1 = pd.read_csv(input_1)\n",
    "\n",
    "# data1[\"log10(PValue)\"] = -1*np.log10(data1[\"P.Value\"])\n",
    "data1[\"expression\"] = \"Not differentially expressed\"\n",
    "data1.loc[((data1[\"P.Value\"]<pvalue) &(data1[\"Log FC\"]>logFC)), \"expression\"]= \"Upregulated\"\n",
    "data1.loc[((data1[\"P.Value\"]<pvalue) &(data1[\"Log FC\"]< -1*logFC)), \"expression\"]= \"Downregulated\"\n",
    "data1[[\"BP\", \"CC\", \"MF\"]] = \"\"\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?visuz.GeneExpression.volcano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volcano plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visuz.GeneExpression.volcano(df=data1, \n",
    "                             lfc=\"Log FC\",\n",
    "                             lfc_thr=(logFC,logFC),# For left and right\n",
    "                             pv=\"P.Value\", \n",
    "                             show=True,\n",
    "                             gfont=18,\n",
    "                             axtickfontsize=18,\n",
    "                             axlabelfontsize=18,\n",
    "                             dim=(20, 16),\n",
    "                             pv_thr=(pvalue,pvalue), # For left and right\n",
    "                             geneid='Gene', \n",
    "                             figname='volcano',\n",
    "                             genenames=(\"DNAH2\", \"SIGIRR\"), # Just random selected genes Can be cnaged for significat genes\n",
    "                             plotlegend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Gene2go\n",
    "\n",
    "Note: wget must be in system path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!wget -c ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/gene2go.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ncbi_gene_results_to_python.py is part of [goatools](https://github.com/tanghaibao/goatools/blob/main/scripts/ncbi_gene_results_to_python.py)which generates genes_ncbi_human_proteincoding.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ncbi_gene_results_to_python.py -o genes_ncbi_human_proteincoding.py $input_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step can not be performed earlier\n",
    "from genes_ncbi_human_proteincoding import GENEID2NT as GeneID2nt_hum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -c ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/gene2go.gz\n",
    "!gunzip -f gene2go.gz\n",
    "obo_fname = download_go_basic_obo()\n",
    "fin_gene2go = download_ncbi_associations()\n",
    "obodag = GODag(\"go-basic.obo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {}\n",
    "\n",
    "for key in GeneID2nt_hum:\n",
    "    mapper[GeneID2nt_hum[key].Symbol] = GeneID2nt_hum[key].GeneID\n",
    "    \n",
    "inv_map = {v: k for k, v in mapper.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inv_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read NCBI's gene2go. Store annotations in a list of namedtuples\n",
    "objanno = Gene2GoReader(fin_gene2go, taxids=[10090]) # 9606 is for humans\n",
    "# Get namespace2association where:\n",
    "#    namespace is:\n",
    "#        BP: biological_process               \n",
    "#        MF: molecular_function\n",
    "#        CC: cellular_component\n",
    "#    assocation is a dict:\n",
    "#        key: NCBI GeneID\n",
    "#        value: A set of GO IDs associated with that gene\n",
    "ns2assoc = objanno.get_ns2assc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goeaobj = GOEnrichmentStudyNS(\n",
    "        GeneID2nt_hum.keys(), # List of protein-coding genes\n",
    "        ns2assoc, # geneid/GO associations\n",
    "        obodag, # Ontologies\n",
    "        propagate_counts = False,\n",
    "        alpha = 0.05, # default significance cut-off\n",
    "        methods = ['fdr_bh']) # defult multipletest correction method\n",
    "GO_items = {}\n",
    "\n",
    "grouping = {}\n",
    "grouping[\"BP\"] = {}\n",
    "GO_items[\"BP\"] = []\n",
    "temp = goeaobj.ns2objgoea['BP'].assoc\n",
    "for item in temp:\n",
    "    GO_items[\"BP\"] += temp[item]\n",
    "    for x in temp[item]:\n",
    "        grouping[\"BP\"][x] = item\n",
    "    \n",
    "\n",
    "\n",
    "grouping[\"CC\"] = {}\n",
    "GO_items[\"CC\"] = []\n",
    "temp = goeaobj.ns2objgoea['CC'].assoc\n",
    "for item in temp:\n",
    "    GO_items[\"CC\"] += temp[item]\n",
    "    for x in temp[item]:\n",
    "        grouping[\"CC\"][x] = item\n",
    "\n",
    "grouping[\"MF\"] = {}\n",
    "GO_items[\"MF\"] = []\n",
    "temp = goeaobj.ns2objgoea['MF'].assoc\n",
    "for item in temp:\n",
    "    GO_items[\"MF\"] += temp[item]\n",
    "    for x in temp[item]:\n",
    "        grouping[\"MF\"][x] = item\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pass list of gene symbols\n",
    "def go_it(test_genes, GO_items):\n",
    "    print(f'input genes: {len(test_genes)}')\n",
    "    \n",
    "    mapped_genes = []\n",
    "    for gene in test_genes:\n",
    "        try:\n",
    "            mapped_genes.append(mapper[gene])\n",
    "        except:\n",
    "            pass\n",
    "    print(f'mapped genes: {len(mapped_genes)}')\n",
    "\n",
    "    \n",
    "    goea_results_all = goeaobj.run_study(mapped_genes)\n",
    "    goea_results_sig = [r for r in goea_results_all if r.p_fdr_bh < 0.05]\n",
    "    GO = pd.DataFrame(list(map(lambda x: [x.GO, x.goterm.name, x.goterm.namespace, x.p_uncorrected, x.p_fdr_bh,\\\n",
    "                   x.ratio_in_study[0], x.ratio_in_study[1], GO_items.count(x.GO), list(map(lambda y: inv_map[y], x.study_items)),\\\n",
    "                   ], goea_results_sig)), columns = ['GO', 'term', 'class', 'p', 'p_corr', 'n_genes',\\\n",
    "                                                    'n_study', 'n_go', 'study_genes'])\n",
    "\n",
    "    GO = GO[GO.n_genes > 1]\n",
    "    return GO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upregulated significant genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_u_s = data1[(data1[\"P.Value\"]<0.05)&(data1[\"Log FC\"]<0.0)]\n",
    "genes = data1_u_s.Gene.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GO_items[\"BP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_s_df_fixed_BP = go_it(genes, GO_items[\"BP\"])\n",
    "# u_s_df_fixed_BP = u_s_df_fixed.copy()\n",
    "u_s_df_fixed_BP['per'] = u_s_df_fixed_BP.n_genes/u_s_df_fixed_BP.n_go\n",
    "# u_s_df_fixed_BP = u_s_df_fixed_BP[u_s_df_fixed_BP[\"per\"] != np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.cm.bwr_r\n",
    "norm = mpl.colors.Normalize(vmin = u_s_df_fixed_BP.p_corr.min(), vmax = u_s_df_fixed_BP.p_corr.max())\n",
    "\n",
    "mappr = cm.ScalarMappable(norm = norm, cmap = cm.bwr_r)\n",
    "sm = plt.cm.ScalarMappable(cmap=cm.bwr_r, norm=norm)\n",
    "sm.set_array([])\n",
    "ax = sns.barplot(data = u_s_df_fixed_BP, x = 'per', y = 'term', palette = mappr.to_rgba(u_s_df_fixed_BP.p_corr.values))\n",
    "ax.figure.colorbar(sm)\n",
    "ylim(-1, len(u_s_df_fixed_BP))\n",
    "savefig(\"barplot_BP_upregulated.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: if per is inf, only name will appear in plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_s_df_fixed_BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_group = {}\n",
    "\n",
    "for _, row in u_s_df_fixed_BP[[\"GO\", \"study_genes\"]].iterrows():\n",
    "    for x in row[\"study_genes\"]:\n",
    "        if x in ontology_group:\n",
    "            ontology_group[x].append(row[\"GO\"])\n",
    "        else:\n",
    "            ontology_group[x] = [row[\"GO\"]]\n",
    "            \n",
    "            \n",
    "# ontololu abc\n",
    "ontology_group_type_n_id = {}\n",
    "\n",
    "for x in ontology_group:\n",
    "    ontology_group_type_n_id[x] = {}\n",
    "    for go in ontology_group[x]:\n",
    "        for gp in [\"BP\"]:\n",
    "            ontology_group_type_n_id[x][gp] = []\n",
    "            if go in grouping[gp]:\n",
    "                ontology_group_type_n_id[x][gp].append(grouping[gp][go])\n",
    "                \n",
    "                \n",
    "for gene in ontology_group_type_n_id:\n",
    "    for tp in ontology_group_type_n_id[gene]:\n",
    "        u_s_df_fixed_BP.loc[data1[\"Gene\"]==gene, tp] = \",\".join(map(str,ontology_group_type_n_id[gene][tp]))\n",
    "\n",
    "u_s_df_fixed_BP.to_csv(\"Final_table_BP_upregulated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_s_df_fixed_MF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_s_df_fixed_MF = go_it(genes, GO_items[\"MF\"])\n",
    "# u_s_df_fixed_BP = u_s_df_fixed.copy()\n",
    "u_s_df_fixed_MF['per'] = u_s_df_fixed_MF.n_genes/u_s_df_fixed_MF.n_go\n",
    "# u_s_df_fixed_BP = u_s_df_fixed_BP[u_s_df_fixed_BP[\"per\"] != np.inf]\n",
    "\n",
    "cmap = mpl.cm.bwr_r\n",
    "norm = mpl.colors.Normalize(vmin = u_s_df_fixed_MF.p_corr.min(), vmax = u_s_df_fixed_MF.p_corr.max())\n",
    "\n",
    "mappr = cm.ScalarMappable(norm = norm, cmap = cm.bwr_r)\n",
    "sm = plt.cm.ScalarMappable(cmap=cm.bwr_r, norm=norm)\n",
    "sm.set_array([])\n",
    "ax = sns.barplot(data = u_s_df_fixed_MF, x = 'per', y = 'term', palette = mappr.to_rgba(u_s_df_fixed_MF.p_corr.values))\n",
    "ax.figure.colorbar(sm)\n",
    "ylim(-1, len(u_s_df_fixed_MF))\n",
    "savefig(\"barplot_MF_upregulated.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_group = {}\n",
    "\n",
    "for _, row in u_s_df_fixed_MF[[\"GO\", \"study_genes\"]].iterrows():\n",
    "    for x in row[\"study_genes\"]:\n",
    "        if x in ontology_group:\n",
    "            ontology_group[x].append(row[\"GO\"])\n",
    "        else:\n",
    "            ontology_group[x] = [row[\"GO\"]]\n",
    "            \n",
    "            \n",
    "# ontololu abc\n",
    "ontology_group_type_n_id = {}\n",
    "\n",
    "for x in ontology_group:\n",
    "    ontology_group_type_n_id[x] = {}\n",
    "    for go in ontology_group[x]:\n",
    "        for gp in [\"MF\"]:\n",
    "            ontology_group_type_n_id[x][gp] = []\n",
    "            if go in grouping[gp]:\n",
    "                ontology_group_type_n_id[x][gp].append(grouping[gp][go])\n",
    "                \n",
    "                \n",
    "for gene in ontology_group_type_n_id:\n",
    "    for tp in ontology_group_type_n_id[gene]:\n",
    "        u_s_df_fixed_MF.loc[data1[\"Gene\"]==gene, tp] = \",\".join(map(str,ontology_group_type_n_id[gene][tp]))\n",
    "\n",
    "u_s_df_fixed_MF.to_csv(\"Final_table_MF_upregulated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "u_s_df_fixed_CC = go_it(genes, GO_items[\"CC\"])\n",
    "# u_s_df_fixed_BP = u_s_df_fixed.copy()\n",
    "u_s_df_fixed_CC['per'] = u_s_df_fixed_CC.n_genes/u_s_df_fixed_CC.n_go\n",
    "# u_s_df_fixed_BP = u_s_df_fixed_BP[u_s_df_fixed_BP[\"per\"] != np.inf]\n",
    "\n",
    "cmap = mpl.cm.bwr_r\n",
    "norm = mpl.colors.Normalize(vmin = u_s_df_fixed_CC.p_corr.min(), vmax = u_s_df_fixed_CC.p_corr.max())\n",
    "\n",
    "mappr = cm.ScalarMappable(norm = norm, cmap = cm.bwr_r)\n",
    "sm = plt.cm.ScalarMappable(cmap=cm.bwr_r, norm=norm)\n",
    "sm.set_array([])\n",
    "ax = sns.barplot(data = u_s_df_fixed_CC, x = 'per', y = 'term', palette = mappr.to_rgba(u_s_df_fixed_CC.p_corr.values))\n",
    "ax.figure.colorbar(sm)\n",
    "ylim(-1, len(u_s_df_fixed_CC))\n",
    "savefig(\"barplot_MF_upregulated.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_group = {}\n",
    "\n",
    "for _, row in u_s_df_fixed_CC[[\"GO\", \"study_genes\"]].iterrows():\n",
    "    for x in row[\"study_genes\"]:\n",
    "        if x in ontology_group:\n",
    "            ontology_group[x].append(row[\"GO\"])\n",
    "        else:\n",
    "            ontology_group[x] = [row[\"GO\"]]\n",
    "            \n",
    "            \n",
    "# ontololu abc\n",
    "ontology_group_type_n_id = {}\n",
    "\n",
    "for x in ontology_group:\n",
    "    ontology_group_type_n_id[x] = {}\n",
    "    for go in ontology_group[x]:\n",
    "        for gp in [\"MF\"]:\n",
    "            ontology_group_type_n_id[x][gp] = []\n",
    "            if go in grouping[gp]:\n",
    "                ontology_group_type_n_id[x][gp].append(grouping[gp][go])\n",
    "                \n",
    "                \n",
    "for gene in ontology_group_type_n_id:\n",
    "    for tp in ontology_group_type_n_id[gene]:\n",
    "        u_s_df_fixed_CC.loc[data1[\"Gene\"]==gene, tp] = \",\".join(map(str,ontology_group_type_n_id[gene][tp]))\n",
    "\n",
    "u_s_df_fixed_CC.to_csv(\"Final_table_CC_upregulated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down regulated significant genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_d_s = data1[(data1[\"P.Value\"]<0.05)&(data1[\"Log FC\"]>0.0)]\n",
    "genes = data1_d_s.Gene.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_s_df_fixed_BP = go_it(genes,  GO_items[\"BP\"])\n",
    "d_s_df_fixed_BP['per'] = d_s_df_fixed_BP.n_genes/d_s_df_fixed_BP.n_go\n",
    "\n",
    "\n",
    "cmap = mpl.cm.bwr_r\n",
    "norm = mpl.colors.Normalize(vmin = d_s_df_fixed_BP.p_corr.min(), vmax = d_s_df_fixed_BP.p_corr.max())\n",
    "\n",
    "mappr = cm.ScalarMappable(norm = norm, cmap = cm.bwr_r)\n",
    "sm = plt.cm.ScalarMappable(cmap=cm.bwr_r, norm=norm)\n",
    "sm.set_array([])\n",
    "ax = sns.barplot(data = d_s_df_fixed_BP, x = 'per', y = 'term', palette = mappr.to_rgba(d_s_df_fixed_BP.p_corr.values))\n",
    "ax.figure.colorbar(sm)\n",
    "ylim(-1, len(d_s_df_fixed_BP))\n",
    "savefig(\"barplot_BP_downregulated.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_group = {}\n",
    "\n",
    "for _, row in d_s_df_fixed_BP[[\"GO\", \"study_genes\"]].iterrows():\n",
    "    for x in row[\"study_genes\"]:\n",
    "        if x in ontology_group:\n",
    "            ontology_group[x].append(row[\"GO\"])\n",
    "        else:\n",
    "            ontology_group[x] = [row[\"GO\"]]\n",
    "            \n",
    "            \n",
    "# ontololu abc\n",
    "ontology_group_type_n_id = {}\n",
    "\n",
    "for x in ontology_group:\n",
    "    ontology_group_type_n_id[x] = {}\n",
    "    for go in ontology_group[x]:\n",
    "        for gp in [\"BP\"]:\n",
    "            ontology_group_type_n_id[x][gp] = []\n",
    "            if go in grouping[gp]:\n",
    "                ontology_group_type_n_id[x][gp].append(grouping[gp][go])\n",
    "                \n",
    "                \n",
    "for gene in ontology_group_type_n_id:\n",
    "    for tp in ontology_group_type_n_id[gene]:\n",
    "        d_s_df_fixed_BP.loc[data1[\"Gene\"]==gene, tp] = \",\".join(map(str,ontology_group_type_n_id[gene][tp]))\n",
    "\n",
    "d_s_df_fixed_BP.to_csv(\"Final_table_BP_downregulated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_s_df_fixed_MF = go_it(genes,  GO_items[\"MF\"])\n",
    "d_s_df_fixed_MF['per'] = d_s_df_fixed_MF.n_genes/d_s_df_fixed_MF.n_go\n",
    "\n",
    "\n",
    "cmap = mpl.cm.bwr_r\n",
    "norm = mpl.colors.Normalize(vmin = d_s_df_fixed_MF.p_corr.min(), vmax = d_s_df_fixed_MF.p_corr.max())\n",
    "\n",
    "mappr = cm.ScalarMappable(norm = norm, cmap = cm.bwr_r)\n",
    "sm = plt.cm.ScalarMappable(cmap=cm.bwr_r, norm=norm)\n",
    "sm.set_array([])\n",
    "ax = sns.barplot(data = d_s_df_fixed_MF, x = 'per', y = 'term', palette = mappr.to_rgba(d_s_df_fixed_MF.p_corr.values))\n",
    "ax.figure.colorbar(sm)\n",
    "ylim(-1, len(d_s_df_fixed_MF))\n",
    "savefig(\"barplot_MF_downregulated.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_group = {}\n",
    "\n",
    "for _, row in d_s_df_fixed_MF[[\"GO\", \"study_genes\"]].iterrows():\n",
    "    for x in row[\"study_genes\"]:\n",
    "        if x in ontology_group:\n",
    "            ontology_group[x].append(row[\"GO\"])\n",
    "        else:\n",
    "            ontology_group[x] = [row[\"GO\"]]\n",
    "            \n",
    "            \n",
    "# ontololu abc\n",
    "ontology_group_type_n_id = {}\n",
    "\n",
    "for x in ontology_group:\n",
    "    ontology_group_type_n_id[x] = {}\n",
    "    for go in ontology_group[x]:\n",
    "        for gp in [\"MF\"]:\n",
    "            ontology_group_type_n_id[x][gp] = []\n",
    "            if go in grouping[gp]:\n",
    "                ontology_group_type_n_id[x][gp].append(grouping[gp][go])\n",
    "                \n",
    "                \n",
    "for gene in ontology_group_type_n_id:\n",
    "    for tp in ontology_group_type_n_id[gene]:\n",
    "        d_s_df_fixed_MF.loc[data1[\"Gene\"]==gene, tp] = \",\".join(map(str,ontology_group_type_n_id[gene][tp]))\n",
    "\n",
    "d_s_df_fixed_MF.to_csv(\"Final_table_MF_downregulated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_s_df_fixed_CC = go_it(genes,  GO_items[\"CC\"])\n",
    "d_s_df_fixed_CC['per'] = d_s_df_fixed_CC.n_genes/d_s_df_fixed_CC.n_go\n",
    "\n",
    "\n",
    "cmap = mpl.cm.bwr_r\n",
    "norm = mpl.colors.Normalize(vmin = d_s_df_fixed_CC.p_corr.min(), vmax = d_s_df_fixed_CC.p_corr.max())\n",
    "\n",
    "mappr = cm.ScalarMappable(norm = norm, cmap = cm.bwr_r)\n",
    "sm = plt.cm.ScalarMappable(cmap=cm.bwr_r, norm=norm)\n",
    "sm.set_array([])\n",
    "ax = sns.barplot(data = d_s_df_fixed_CC, x = 'per', y = 'term', palette = mappr.to_rgba(d_s_df_fixed_CC.p_corr.values))\n",
    "ax.figure.colorbar(sm)\n",
    "ylim(-1, len(d_s_df_fixed_CC))\n",
    "savefig(\"barplot_CC_downregulated.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_group = {}\n",
    "\n",
    "for _, row in d_s_df_fixed_CC[[\"GO\", \"study_genes\"]].iterrows():\n",
    "    for x in row[\"study_genes\"]:\n",
    "        if x in ontology_group:\n",
    "            ontology_group[x].append(row[\"GO\"])\n",
    "        else:\n",
    "            ontology_group[x] = [row[\"GO\"]]\n",
    "            \n",
    "            \n",
    "# ontololu abc\n",
    "ontology_group_type_n_id = {}\n",
    "\n",
    "for x in ontology_group:\n",
    "    ontology_group_type_n_id[x] = {}\n",
    "    for go in ontology_group[x]:\n",
    "        for gp in [\"CC\"]:\n",
    "            ontology_group_type_n_id[x][gp] = []\n",
    "            if go in grouping[gp]:\n",
    "                ontology_group_type_n_id[x][gp].append(grouping[gp][go])\n",
    "                \n",
    "                \n",
    "for gene in ontology_group_type_n_id:\n",
    "    for tp in ontology_group_type_n_id[gene]:\n",
    "        d_s_df_fixed_CC.loc[data1[\"Gene\"]==gene, tp] = \",\".join(map(str,ontology_group_type_n_id[gene][tp]))\n",
    "\n",
    "d_s_df_fixed_CC.to_csv(\"Final_table_MF_downregulated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
